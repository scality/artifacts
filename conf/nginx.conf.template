# Reverse-proxy configuration for listing, download, upload, redirect
# operations on a Google Cloud Storage S3 compatible bucket, with some
# additional features to find build depending on prefix and status, and
# to trigger batch copy operations.

# Google Cloud Storage S3 compatible credentials.
env AWS_ACCESS_KEY_ID;
env AWS_SECRET_ACCESS_KEY;

# Github basic auth checks.
env GITHUB_API_COMPANY;
env GITHUB_API_ENABLED;
env GITHUB_USER_ALLOWED_UPLOAD;
env BOT_USERNAME;
env BOT_TOKEN;

# Google Cloud Storage S3 compatible bucket prefix.
env AWS_BUCKET_PREFIX;

# It is recommended to set one worker process per CPU core.
worker_processes 2;

# The maximum number of connections allowed to a worker.
events {
  worker_connections 1024;
}

http {
  # Uncomment the line below to enable some debug.
  #
  # error_log /dev/stderr debug;

  # Define a format that will also log cache hit or miss in access_log. This
  # is based on the combined format (enabled by default), where it adds the
  # cache status and removes the remote user info.
  #
  log_format access_cache '$remote_addr - $upstream_cache_status [$time_local] '
                         '"$request" $status $body_bytes_sent '
                         '"$http_referer" "$http_user_agent" '
                         '($upstream_response_time)';
  access_log /dev/stdout access_cache;
  access_by_lua_file "/etc/nginx/github_access.ljbc";

  # Mandatory directive to run lua stuff.
  #
  lua_package_path "/usr/local/lib/lua/?.lua;;";

  # Do not resolve in IPv6.
  #
  resolver 8.8.8.8 valid=300s ipv6=off;

  # The upstream will handle a pool of keep-alive connections to the backend
  # and it will also be used to handle the retries on backend errors.
  #
  upstream ${AWS_BUCKET_PREFIX}-staging {

    # We set up a pool of two servers which both define the same backend in
    # order to give to the retry mechanism (configured in /download and /upload
    # locations) a chance to use another server in the pool on error. As
    # backend errors are expected to be transient, it is OK to retry on the
    # same backend.
    #
    # Speaking of transient errors, we have to disable the nginx internal
    # mechanism of servers blacklisting when errors are encountered. This is
    # achieved by setting the max_fails option to 0. This way, we authorize an
    # unlimited amound of errors before blacklisting the server and as a
    # consequence it will never be blacklisted.
    #
    # Nginx resolves backends at start and reload only and ignores the
    # resolver settings at this stage. So, we can not limit the resolution to
    # IPv4, which generates flaky connect() errors leading to 502 errors. We
    # can fix this by forcing a resolution ourselves before the nginx launch
    # and fill the configuration with the IPv4.
    #
    # Please note that in the commercial version, there is a "resolve" option
    # to the "server" directive that uses the resolver to handle the
    # resolution. This may be ported to the open source version someday.
    #
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_STAGING_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;

    # Max number of unused keep-alive connections kept open per worker process
    # for the pool.
    #
    keepalive 16;

    # Max number of requests per connection.
    #
    keepalive_requests 256;

    # Max time of inactivity per connection.
    #
    keepalive_timeout 60s;
  }

  upstream ${AWS_BUCKET_PREFIX}-prolonged {
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROLONGED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;

    keepalive 16;
    keepalive_requests 256;
    keepalive_timeout 60s;
  }

  upstream ${AWS_BUCKET_PREFIX}-promoted {
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_PROMOTED_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;
    server __S3_ENDPOINT_GENERIC_IPV4__:__S3_ENDPOINT_PORT__ max_fails=0 backup;

    keepalive 16;
    keepalive_requests 256;
    keepalive_timeout 60s;
  }

  # Do not store client request body before sending it via proxy_pass.
  #
  proxy_request_buffering off;

  # Enable retry for connect, timeout (we do not retry on something else
  # as we do not store the request body).
  #
  proxy_next_upstream error timeout;

  # Limit number of retries to 10.
  #
  proxy_next_upstream_tries 10;

  # This map will be used to force a "Content-type" header depending on the
  # proxyfied object extension. If no extension is found or no extension is
  # matching, a value of "application/binary" will be set.
  #
  include /etc/nginx/mimetypes.map;

  server {
    # Use plain HTTP, as we are on a private network.
    #
    listen 80;

    # Do not limit the size of an uploaded object.
    #
    client_max_body_size 0;

    # Mandatory to support keep-alive connections.
    #
    proxy_http_version 1.1;

    # Be more patient instead of retry.
    #
    proxy_read_timeout 600s;
    proxy_send_timeout 600s;
    proxy_connect_timeout 600s;

    # do not merge slashes, and send 404 to urls with
    # double slashes.
    merge_slashes off;
    location ~ // {
      return 404;
    }

    # Handle status module.
    #
    location /nginx_status {
      stub_status;
    }

    # Handle "latest" feature.
    #
    location ~ ^/latest/(.*)$ {
      set $prefix $1;
      set $expected_status "";

      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      rewrite_by_lua_file /etc/nginx/find_build.ljbc;
    }

    # Handle "last_success" feature.
    #
    location ~ ^/last_success/(.*)$ {
      set $prefix $1;
      set $expected_status "SUCCESSFUL";

      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      rewrite_by_lua_file /etc/nginx/find_build.ljbc;
    }

    # Handle "last_failure" feature.
    #
    location ~ ^/last_failure/(.*)$ {
      set $prefix $1;
      set $expected_status "FAILED";

      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      rewrite_by_lua_file /etc/nginx/find_build.ljbc;
    }

    # Handle browsing per project.
    #
    location ~ ^/github/scality/([^/]+)/(builds|download)/(.*)$ {
      proxy_pass http://127.0.0.1/download/$3$is_args$args;
      proxy_set_header Host $host;
      proxy_set_header Script-Name /github/scality/$1/;
    }

    # Redirect a url listing a container not ended by a slash to the same url
    # with a trailing slash.
    #
    rewrite ^/builds/([^/]+)$ $http_script_name/builds/$1/ permanent;
    rewrite ^/download/([^/]+)$ $http_script_name/download/$1/ permanent;

    # Redirect "/" location to "/builds/" to keep backward compatibility
    # with the previous artifacts implementations.
    #
    rewrite ^/$ $http_script_name/builds/ permanent;

    # Handle "/builds/" location to keep backward compatibility with the
    # previous artifacts implementations.
    #
    rewrite ^/builds/(.*)$ /download/$1 last;

    # Handle subdir listing under "/redirect/"
    #
    rewrite ^/redirect/(.*/)$ /download/$1 last;

    # Handle "/search/" API
    #
    rewrite ^/search/(.*)$ /search_metadata/$1 last;

    # Hack
    #
    # ngx.location.capture() does not allow request to external url.
    #
    # To solve this, a specific location has been added for that will redirect
    # a real request by using a proxy_pass to a full url.
    #
    location /force_github_request/ {
      # Not exposed to external requests.
      internal;

      # Remove all request headers but Authorization
      access_by_lua_block {
        for header_key, header_value in pairs(ngx.req.get_headers()) do
          if header_key ~= "authorization" then
            ngx.req.clear_header(header_key)
          end
        end
      }

      # We need a valid and known user-agent otherwise github rejects the request
      proxy_set_header User-Agent "curl/7.83.1";

      # Tell gihub we do not want compressed body in its response
      proxy_set_header Accept-Encoding identity;

      proxy_set_header Accept application/vnd.github.v3+json;
      proxy_set_header Host api.github.com;

      proxy_pass __GITHUB_API_URL__/;
    }

    # Hack
    #
    # For some unknown reason the subrequest initiated by the lua call
    # ngx.location.capture() does not receive its content transformed by the
    # xslt module (probably due to some subrequest implementation choice for
    # the sake of optimization). I also noticed some other issues and suspect
    # that you can not trust some nginx vars in the context of a subrequest.
    #
    # To solve this, a specific location has been added for that will force a
    # real request by using a proxy_pass to a full url.
    #
    location /force_real_request/ {
      # Not exposed to external requests.
      #
      internal;

      rewrite ^/force_real_request(.*)$ $1 break;

      proxy_pass http://127.0.0.1;
      proxy_set_header Host $host;
    }

    # Handle the builds listing refresh.
    #
    location ~ ^/refresh_full_listing/$ {
      if ($request_method != GET) {
        return 400;
      }

      # Not allowed from outside the container.
      #
      if ($remote_addr != 127.0.0.1) {
        return 400;
      }

      # Process browse.
      #
      set $canonical_path "";
      set $full_listing_mode "UPSTREAM";
      content_by_lua_file /etc/nginx/browse.ljbc;
    }

    # Handle the builds listing.
    #
    location ~ ^/download/$ {
      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      # Process browse.
      #
      set $canonical_path "";
      set $full_listing_mode "CACHE";
      content_by_lua_file /etc/nginx/browse.ljbc;
    }

    # Handle the browsing inside a build.
    #
    location ~ ^/download/(.+/)$ {
      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      # Canonicalize path.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      #
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]*$') {
        return 400;
      }

      # Process browse.
      #
      content_by_lua_file /etc/nginx/browse.ljbc;
    }

    # Process listing in raw format.
    #
    # query_string optionnal args:
    #   delimiter
    #   marker
    #   bucket
    location ~ ^/browse_raw/(|.*/)$ {
      if ($request_method != GET) {
        return 400;
      }

      # Not allowed from outside the container.
      #
      if ($remote_addr != 127.0.0.1) {
        return 400;
      }

      # Canonicalize path.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]*$') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode "LISTING";
      set $aws_access_key "";
      set $aws_signature  "";
      set $x_amz_date     "";
      set $aws_tgt_bucket "$arg_bucket";
      set $encoded_prefix "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;

      # Set S3 headers for the request send to the backend.
      #
      proxy_set_header Authorization "AWS $aws_access_key:$aws_signature";
      proxy_set_header x-amz-date $x_amz_date;

      # Mandatory otherwise the upstream name will be considered as a part of
      # the uri when the resquest will be processed in the upstream.
      #
      proxy_set_header Host $aws_tgt_bucket.__S3_ENDPOINT_HOST__;

      # Enabled keep-alive to backend.
      #
      proxy_set_header Connection "keep-alive";

      # Proxy request to upstream "keepalivepool".
      #
      proxy_pass __S3_ENDPOINT_PROTO__$aws_tgt_bucket/?prefix=$encoded_prefix&delimiter=$arg_delimiter&marker=$arg_marker;

      # Filter out XML in raw format.
      #
      xslt_types application/xml;
      xslt_stylesheet /etc/nginx/browse.raw.xslt;
      xslt_string_param listing_path $canonical_path;
    }

    # Redirect to an object.
    #
    location ~ ^/redirect/([^/]+/.*[^/])$ {
      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode       "PRESIGN";
      set $redirect_endpoint    "__S3_ENDPOINT_PROTO____S3_ENDPOINT_HOST__:__S3_ENDPOINT_PORT__";
      set $aws_tgt_bucket       "";
      set $encoded_key          "";
      set $presign_query_string "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;
    }

    # This will be called to send a generic 404 body instead of the XML body
    # sent by the upstream.
    #
    location @not_found {
      return 404;
    }

    # Download an object.
    #
    location ~ ^/download/([^/]+/.*[^/])$ {
      if ($request_method !~ ^(GET|HEAD)$) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode "DOWNLOAD";
      set $aws_access_key "";
      set $aws_signature  "";
      set $x_amz_date     "";
      set $aws_tgt_bucket "";
      set $encoded_key    "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;

      # Set S3 headers for the request send to the backend.
      #
      proxy_set_header Authorization "AWS $aws_access_key:$aws_signature";
      proxy_set_header x-amz-date $x_amz_date;

      # Mandatory otherwise the upstream name will be considered as a part of
      # the uri when the resquest will be processed in the upstream.
      #
      proxy_set_header Host $aws_tgt_bucket.__S3_ENDPOINT_HOST__;

      # Enabled keep-alive to backend.
      #
      proxy_set_header Connection "keep-alive";

      # This will let nginx override the 404 error body sent by upstream in
      # XML with its own content.
      #
      proxy_intercept_errors on;
      error_page 404 @not_found;

      # Do not mess the browser with generic Content-type from the S3 storage.
      #
      proxy_hide_header Content-type;
      set_by_lua_block $file_extension { return string.match(ngx.var.canonical_path, "%.[A-Za-z0-9]+$") }
      add_header Content-type $file_mime_type;

      # Proxy request to upstream "keepalivepool".
      #
      proxy_pass __S3_ENDPOINT_PROTO__$aws_tgt_bucket/$encoded_key;
    }

    # Check an object without downloading it.
    #
    # For some reason that I did not understand, HEAD is failing with 403 againt GCS
    # In order to have a fast way to check if an object exist without a possibly expensive
    # listing or download, we can do a GET on a short range without caching
    #
    # Will return 416 if the object exists (the range header is invalid on purpose)
    # Will return 404 if the object does not exist
    #
    location ~ ^/check_raw/([^/]+/.*[^/])$ {
      if ($request_method != GET) {
        return 400;
      }

      # Not allowed from outside the container.
      #
      if ($remote_addr != 127.0.0.1) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode "DOWNLOAD";
      set $aws_access_key "";
      set $aws_signature  "";
      set $x_amz_date     "";
      set $aws_tgt_bucket "";
      set $encoded_key    "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;

      # Set S3 headers for the request send to the backend.
      #
      proxy_set_header Authorization "AWS $aws_access_key:$aws_signature";
      proxy_set_header x-amz-date $x_amz_date;

      # Mandatory otherwise the upstream name will be considered as a part of
      # the uri when the resquest will be processed in the upstream.
      #
      proxy_set_header Host $aws_tgt_bucket.__S3_ENDPOINT_HOST__;

      # Enabled keep-alive to backend.
      #
      proxy_set_header Connection "keep-alive";

      # Set the shortest range we can.
      #
      proxy_set_header Range "bytes=-0";

      # Proxy request to upstream "keepalivepool".
      #
      proxy_pass __S3_ENDPOINT_PROTO__$aws_tgt_bucket/$encoded_key;
    }

    # Copy an object wih the following syntax:
    #
    # /src_build/tgt_build/object_path
    #
    # if object_path matches .ARTIFACTS_BEFORE/[d]+/(.*), the source will be $1 from regexp.
    #
    location ~ ^/copy/[^/]+/[^/]+/.*[^/]$ {
      if ($request_method != PUT) {
        return 400;
      }

      # Not allowed from outside the container.
      #
      if ($remote_addr != 127.0.0.1) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode    "COPY";
      set $aws_access_key    "";
      set $aws_signature     "";
      set $x_amz_date        "";
      set $x_amz_copy_source "";
      set $aws_tgt_bucket    "";
      set $encoded_key       "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;

      # Set S3 headers for the request send to the backend.
      #
      proxy_set_header Authorization     "AWS $aws_access_key:$aws_signature";
      proxy_set_header x-amz-date        $x_amz_date;
      proxy_set_header x-amz-copy-source $x_amz_copy_source;

      # Mandatory otherwise the upstream name will be considered as a part of
      # the uri when the resquest will be processed in the upstream.
      #
      proxy_set_header Host $aws_tgt_bucket.__S3_ENDPOINT_HOST__;

      # Enabled keep-alive to backend.
      #
      proxy_set_header Connection "keep-alive";

      # Proxy request to upstream "keepalivepool".
      #
      proxy_pass __S3_ENDPOINT_PROTO__$aws_tgt_bucket/$encoded_key;
    }

    # Copy a build.
    #
    location ~ ^/copy/[^/]+/[^/]+/$ {
      if ($request_method != GET) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process build copy.
      #
      content_by_lua_file /etc/nginx/copy_build.ljbc;
    }

    # Version an object with the following syntax:
    #
    # /version/object_path
    #
    location ~ ^/version/([0-9]+)/([^/]+/.*[^/])$ {
      if ($request_method != GET) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process object versioning.
      #
      content_by_lua_file /etc/nginx/version_object.ljbc;
    }

    # Put an object.
    #
    location ~ ^/upload/([^/]+/.*[^/])$ {
      if ($request_method != PUT) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Check that we are uploading an object to a staging build or to metadata
      if ($canonical_path !~ '^([^/]+\:staging\-([0-9]{10}\.|)[0-9a-f]+\.[^./]+\.[0-9]+(\.[0-9]+|)|\.md_staging)/') {
        return 400;
      }

      # Process AWS S3 signature.
      #
      set $signature_mode "UPLOAD";
      set $aws_access_key "";
      set $aws_signature  "";
      set $x_amz_date     "";
      set $x_amz_acl      "";
      set $aws_tgt_bucket "${AWS_BUCKET_PREFIX}-staging";
      set $encoded_key    "";
      rewrite_by_lua_file /etc/nginx/compute_aws_s3_signature.ljbc;

      # Set S3 headers for the request send to the backend.
      #
      proxy_set_header Authorization "AWS $aws_access_key:$aws_signature";
      proxy_set_header x-amz-date    $x_amz_date;
      proxy_set_header x-amz-acl     $x_amz_acl;

      # Mandatory otherwise the upstream name will be considered as a part of
      # the uri when the resquest will be processed in the upstream.
      #
      proxy_set_header Host $aws_tgt_bucket.__S3_ENDPOINT_HOST__;

      # Enabled keep-alive to backend.
      #
      proxy_set_header Connection "keep-alive";

      # This will prevent the object to be cached in the Google Cloud Storage
      # infrastructure when it will be downloaded.
      #
      proxy_set_header Cache-Control "no-cache";
      proxy_set_header Cache-Control "no-store";

      # Proxy request to upstream "keepalivepool".
      #
      proxy_pass __S3_ENDPOINT_PROTO__$aws_tgt_bucket/$encoded_key;
    }

    # Add metadata for a build with the following syntax:
    #
    # /github/scality/$(repo)/$(workflow_name)/$(created_at)/$(artifacts_name)?key1=value1&key1=value2&key2=value3
    #
    location ~ ^/add_metadata/(.+) {
      if ($request_method != GET) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process metadata update.
      #
      content_by_lua_file /etc/nginx/add_metadata.ljbc;
    }

    # Search a build from metadata with the followg syntax:
    #
    # /(list|latest|last_success)/(branch|commit|version|whatever)/github/scality/$(repo)/$(workflow_name)/$(value)
    #
    location ~ ^/search_metadata/ {
      if ($request_method != GET) {
        return 400;
      }

      # Canonicalize key.
      #
      set_by_lua_file $canonical_path /etc/nginx/canonicalize_path.ljbc;

      # Apply charset whitelist filtering.
      if ($canonical_path !~ '^[__SUPPORTED_CHARSET__]+$') {
        return 400;
      }

      # Process metadata query.
      #
      content_by_lua_file /etc/nginx/search_metadata.ljbc;
    }
  }
}
